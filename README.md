# iac_offline

Git Repo
â”‚
â”œâ”€ jmeter/
â”‚   â”œâ”€ bin/                 (offline bundle)
â”‚   â”œâ”€ lib/
â”‚   â”œâ”€ plugins/
â”‚
â”œâ”€ java/
â”‚   â””â”€ jdk.tar.gz
â”‚
â”œâ”€ config/
â”‚   â”œâ”€ master/
â”‚   â”‚   â””â”€ jmeter.properties
â”‚   â”œâ”€ slave/
â”‚   â”‚   â””â”€ jmeter.properties
â”‚
â”œâ”€ scripts/
â”‚   â”œâ”€ install_java.sh
â”‚   â”œâ”€ install_jmeter.sh
â”‚   â”œâ”€ configure_master.sh
â”‚   â”œâ”€ configure_slave.sh
â”‚   â”œâ”€ start_slave.sh
â”‚   â””â”€ validate_cluster.sh
â”‚
â””â”€ pipelines/
    â””â”€ setup-jmeter.yml


ğŸ”§ Paso 1 â€” Empaquetar JMeter (offline)

Desde una mÃ¡quina con internet:

Descargas:

JDK (misma versiÃ³n)

Apache JMeter

Plugins necesarios

Los comprimes:

tar -czf jmeter-bundle.tar.gz apache-jmeter/


Este bundle se convierte en artefacto.

ğŸ”§ Paso 2 â€” Scripts idempotentes (clave)

Ejemplo: install_jmeter.sh

if [ ! -d /opt/jmeter ]; then
  tar -xzf jmeter-bundle.tar.gz -C /opt
fi


ğŸ‘‰ Puedes correrlo 10 veces y no rompe nada.

ğŸ”§ Paso 3 â€” ConfiguraciÃ³n declarativa
Master:
remote_hosts=10.0.0.32,10.0.0.33
server.rmi.ssl.disable=true

Slaves:
server_port=1099
server.rmi.ssl.disable=true


Copiadas automÃ¡ticamente segÃºn rol.

ğŸ”§ Paso 4 â€” Validaciones automÃ¡ticas

Ejemplo:

nc -z 10.0.0.32 1099
nc -z 10.0.0.33 1099


Fail = pipeline falla.

ğŸš€ Paso 5 â€” Azure DevOps Pipeline (IaC runner)
Pipeline de setup (solo corre cuando hay cambios)
stages:
- stage: SetupJMeter
  jobs:
  - job: ConfigureMaster
    pool: jmeter-master
    steps:
    - script: scripts/install_java.sh
    - script: scripts/install_jmeter.sh
    - script: scripts/configure_master.sh

  - job: ConfigureSlaves
    pool: jmeter-slaves
    steps:
    - script: scripts/install_java.sh
    - script: scripts/install_jmeter.sh
    - script: scripts/configure_slave.sh

Flujo del pipeline para ejecucion de los test

Dev / QA
  â”‚
  â–¼
Git Repo (tests)
  â”‚
  â–¼
Azure DevOps Pipeline
  â”‚
  â”œâ”€ Checkout repo
  â”œâ”€ Copiar tests al Master (.31)
  â”œâ”€ Seleccionar quÃ© test correr
  â”œâ”€ Ejecutar JMeter (CLI)
  â”œâ”€ Recoger resultados
  â””â”€ Publicar artefactos

4ï¸âƒ£ Estructura tÃ­pica del repositorio
jmeter-tests/
â”‚
â”œâ”€ tests/
â”‚   â”œâ”€ login_test.jmx
â”‚   â”œâ”€ checkout_test.jmx
â”‚   â””â”€ search_test.jmx
â”‚
â”œâ”€ data/
â”‚   â”œâ”€ users.csv
â”‚   â””â”€ products.csv
â”‚
â”œâ”€ properties/
â”‚   â”œâ”€ dev.properties
â”‚   â”œâ”€ qa.properties
â”‚   â””â”€ perf.properties
â”‚
â”œâ”€ scripts/
â”‚   â””â”€ run_jmeter.sh
â”‚
â””â”€ azure-pipelines.yml

1ï¸âƒ£2ï¸âƒ£ Flujo visual final
Git (tests)
   â”‚
   â–¼
Azure Pipeline
   â”‚
   â–¼
Agent (.31)
   â”‚
   â–¼
JMeter Master
   â”‚
   â”œâ”€ Slave (.32)
   â””â”€ Slave (.33)

   ğŸ”‘ Reglas de oro (muy importantes)

Tests viven en Git

Pipeline siempre orquesta

JMeter nunca decide

Resultados no se versionan

Master = punto de control


8ï¸âƒ£ Ejemplo REAL de pipeline
trigger: none

parameters:
- name: test
  default: checkout_test.jmx

pool:
  name: jmeter-master

steps:
- checkout: self

- script: |
    /opt/jmeter/bin/jmeter \
      -n \
      -t tests/${{ parameters.test }} \
      -R 10.0.0.32,10.0.0.33 \
      -l results.jtl \
      -e -o report/
  displayName: Run JMeter Test

- publish: report
  artifact: jmeter-report

9ï¸âƒ£ Â¿CÃ³mo JMeter ejecuta realmente?
En el Master (.31):
jmeter -n \
  -t checkout_test.jmx \
  -R slave1,slave2


JMeter:

Lee el .jmx

Distribuye el plan a los slaves

Ejecuta carga desde los slaves

Recoge mÃ©tricas

Genera resultados

ğŸ”Ÿ Â¿CÃ³mo se versiona un cambio de test?

Ejemplo:

Ajustas el ramp-up

Cambias assertions

Cambias timers

ğŸ‘‰ Commit â†’ Push â†’ Pipeline ejecuta nueva versiÃ³n
ğŸ‘‰ Repetible
ğŸ‘‰ Audit trail completo

1ï¸âƒ£1ï¸âƒ£ QuÃ© pasa si agrego un nuevo test

Agregas new_api_test.jmx

Commit a Git

Ejecutas pipeline pasando:

test = new_api_test.jmx


JMeter lo corre

ğŸ“Œ Nada se â€œauto-activaâ€.















1ï¸âƒ£ Arquitectura final â€“ Master, agentes, slaves y tests
ğŸ“ Infra fÃ­sica / lÃ³gica
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Azure DevOps                â”‚
â”‚  - Pipelines                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ JMeter Master (.31)         â”‚
â”‚ - Azure DevOps Agent        â”‚
â”‚ - JMeter CLI                â”‚
â”‚ - Scripts ejecuciÃ³n         â”‚
â”‚ - Workspace de pipelines    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚ RMI
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
     â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Slave (.32) â”‚  â”‚ Slave (.33) â”‚
â”‚ - JMeter    â”‚  â”‚ - JMeter    â”‚
â”‚ - Java      â”‚  â”‚ - Java      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


ğŸ“Œ Reglas claras:

El agente vive solo en el master

Los slaves no conocen Azure DevOps

El pipeline controla al master

JMeter no toma decisiones

2ï¸âƒ£ Flujo de ejecuciÃ³n del pipeline (end-to-end)
Trigger manual / schedule
        â”‚
        â–¼
Stage 1 â€” Prepare
  - Checkout repos
  - Validaciones
        â”‚
        â–¼
Stage 2 â€” Execute Test
  - Run JMeter
  - Distributed load
        â”‚
        â–¼
Stage 3 â€” Validate Results
  - Parse JTL
  - Apply thresholds
        â”‚
        â–¼
Stage 4 â€” Publish
  - Artifacts
  - Metrics (Datadog)
  - Notifications


ğŸ“Œ Pipeline = orquestador total

3ï¸âƒ£ Estructura del pipeline (stages reales)
ğŸ§© Stage 1 â€” Prepare

Objetivo: dejar todo listo y fallar rÃ¡pido si algo estÃ¡ mal.

Checkout repos

Validar conexiÃ³n a slaves

Validar parÃ¡metros

- stage: Prepare
  jobs:
  - job: Precheck
    steps:
    - checkout: self
    - checkout: tests
    - script: scripts/validate_cluster.sh

ğŸ§© Stage 2 â€” Execute

Objetivo: ejecutar exactamente UN test.

- stage: Execute
  jobs:
  - job: RunJMeter
    steps:
    - script: |
        jmeter -n \
          -t tests/$(TEST_FILE) \
          -R $(SLAVES) \
          -l results/results.jtl \
          -e -o report/

ğŸ§© Stage 3 â€” Validate

Objetivo: decidir PASS / FAIL.

Parse .jtl

Evaluar SLAs

Fallar pipeline si no cumple

- stage: Validate
  jobs:
  - job: Evaluate
    steps:
    - script: python scripts/evaluate_results.py

ğŸ§© Stage 4 â€” Publish

Objetivo: sacar resultados fuera del pipeline.

Artifacts

Datadog

Slack / Confluence

4ï¸âƒ£ Estructura del nuevo repositorio (pipelines + config)
ğŸ“¦ Repo: perf-platform
perf-platform/
â”‚
â”œâ”€ pipelines/
â”‚   â”œâ”€ performance.yml
â”‚   â”œâ”€ stress.yml
â”‚   â”œâ”€ endurance.yml
â”‚
â”œâ”€ scripts/
â”‚   â”œâ”€ run_jmeter.sh
â”‚   â”œâ”€ validate_cluster.sh
â”‚   â”œâ”€ evaluate_results.py
â”‚   â””â”€ push_metrics_datadog.py
â”‚
â”œâ”€ config/
â”‚   â”œâ”€ environments/
â”‚   â”‚   â”œâ”€ qa.yml
â”‚   â”‚   â””â”€ perf.yml
â”‚   â”œâ”€ thresholds/
â”‚   â”‚   â”œâ”€ performance.yml
â”‚   â”‚   â”œâ”€ stress.yml
â”‚   â”‚   â””â”€ endurance.yml
â”‚
â””â”€ docs/
    â””â”€ operating-model.md

5ï¸âƒ£ Repo de tests (independiente)
ğŸ“¦ Repo: perf-tests
perf-tests/
â”‚
â”œâ”€ performance/
â”‚   â”œâ”€ login_perf.jmx
â”‚   â””â”€ checkout_perf.jmx
â”‚
â”œâ”€ stress/
â”‚   â”œâ”€ checkout_stress.jmx
â”‚
â”œâ”€ endurance/
â”‚   â”œâ”€ checkout_8h.jmx
â”‚
â”œâ”€ data/
â”‚   â””â”€ users.csv
â”‚
â””â”€ properties/
    â”œâ”€ qa.properties
    â””â”€ perf.properties


ğŸ“Œ Naming define el tipo de test, no lÃ³gica en el .jmx.

6ï¸âƒ£ DiferenciaciÃ³n por tipo de test
Cada pipeline aplica:

DuraciÃ³n

Thresholds

Ramp-up

SLAs

Ejemplo:

Tipo	Pipeline	Threshold
Performance	performance.yml	p95 < 2s
Stress	stress.yml	error < 5%
Endurance	endurance.yml	estabilidad
